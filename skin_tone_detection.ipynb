{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "<ipython-input-1-373f4202c5b8>:107: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfr.fit(X_train,Y_train)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-1-373f4202c5b8>:109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  knn.fit(X_train,Y_train)\n",
      "<ipython-input-1-373f4202c5b8>:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rc.fit(X_train,Y_train)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "rgb_lower = [45,34,30]\n",
    "rgb_higher = [255,219,172]\n",
    "\n",
    "def extractSkin(image):\n",
    "    img = image.copy()\n",
    "    black_img = np.zeros((img.shape[0],img.shape[1],img.shape[2]),dtype=np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_threshold = np.array([0,10, 70], dtype=np.uint8)\n",
    "    upper_threshold = np.array([20, 155, 255], dtype=np.uint8)\n",
    "    skinMask = cv2.inRange(img, lower_threshold, upper_threshold)\n",
    "    skin = cv2.bitwise_and(img, img, mask=skinMask)\n",
    "    return cv2.cvtColor(skin, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def removeBlack(estimator_labels, estimator_cluster):\n",
    "    hasBlack = False\n",
    "    occurance_counter = Counter(estimator_labels)\n",
    "    def compare(x, y): return Counter(x) == Counter(y)\n",
    "    for x in occurance_counter.most_common(len(estimator_cluster)):\n",
    "        color = [int(i) for i in estimator_cluster[x[0]].tolist()]\n",
    "        if compare(color, [0, 0, 0]) == True:\n",
    "            del occurance_counter[x[0]]\n",
    "            hasBlack = True\n",
    "            estimator_cluster = np.delete(estimator_cluster, x[0], 0)\n",
    "            break\n",
    "    return (occurance_counter, estimator_cluster, hasBlack)\n",
    "\n",
    "def getColorInformation(estimator_labels, estimator_cluster, hasThresholding=False):\n",
    "    occurance_counter = None\n",
    "    colorInformation = []\n",
    "    hasBlack = False\n",
    "    if hasThresholding == True:\n",
    "        (occurance, cluster, black) = removeBlack(\n",
    "            estimator_labels, estimator_cluster)\n",
    "        occurance_counter = occurance\n",
    "        estimator_cluster = cluster\n",
    "        hasBlack = black\n",
    "    else:\n",
    "        occurance_counter = Counter(estimator_labels)\n",
    "    totalOccurance = sum(occurance_counter.values())\n",
    "    for x in occurance_counter.most_common(len(estimator_cluster)):\n",
    "        index = (int(x[0]))\n",
    "        index = (index-1) if ((hasThresholding & hasBlack)\n",
    "                              & (int(index) != 0)) else index\n",
    "        color = estimator_cluster[index].tolist()\n",
    "        color_percentage = (x[1]/totalOccurance)\n",
    "        colorInfo = {\"cluster_index\": index, \"color\": color,\n",
    "                     \"color_percentage\": color_percentage}\n",
    "        colorInformation.append(colorInfo)\n",
    "    return colorInformation\n",
    "\n",
    "def extractDominantColor(image, number_of_colors=1, hasThresholding=False):\n",
    "    if hasThresholding == True:\n",
    "        number_of_colors += 1\n",
    "    img = image.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.reshape((img.shape[0]*img.shape[1]), 3)\n",
    "    estimator = KMeans(n_clusters=number_of_colors, random_state=0)\n",
    "    estimator.fit(img)\n",
    "    colorInformation = getColorInformation(\n",
    "        estimator.labels_, estimator.cluster_centers_, hasThresholding)\n",
    "    return colorInformation\n",
    "\n",
    "def plotColorBar(colorInformation):\n",
    "    color_bar = np.zeros((100, 500, 3), dtype=\"uint8\")\n",
    "    top_x = 0\n",
    "    for x in colorInformation:\n",
    "        bottom_x = top_x + (x[\"color_percentage\"] * color_bar.shape[1])\n",
    "        color = tuple(map(int, (x['color'])))\n",
    "        cv2.rectangle(color_bar, (int(top_x), 0),\n",
    "                      (int(bottom_x), color_bar.shape[0]), color, -1)\n",
    "        top_x = bottom_x\n",
    "    return color_bar\n",
    "\n",
    "\n",
    "df=pd.read_csv(r'tone_exe.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['tone']=le.fit_transform(df['TONE'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=df[['R', 'G', 'B']].values\n",
    "Y=df[['tone']].values\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.6)\n",
    "X_train.shape,X_test.shape,Y_train.shape,Y_test.shape\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lr=LogisticRegression()\n",
    "rfr=RandomForestRegressor()\n",
    "svc=SVC()\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "rc=RandomForestClassifier()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "rfr.fit(X_train,Y_train)\n",
    "svc.fit(X_train,Y_train)\n",
    "knn.fit(X_train,Y_train)\n",
    "rc.fit(X_train,Y_train)\n",
    "\n",
    "Y_predlr=lr.predict(X_test)\n",
    "Y_predrfr=rfr.predict(X_test)\n",
    "Y_predsvc=svc.predict(X_test)\n",
    "Y_predknn=knn.predict(X_test)\n",
    "Y_predrc=rc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter image url :data:image/jpeg;base64,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\n",
      "fair\n"
     ]
    }
   ],
   "source": [
    "url = input(\"Enter image url :\")\n",
    "\n",
    "img = imutils.url_to_image(url)\n",
    "# img=cv2.imread('modi.jpg')\n",
    "img = imutils.resize(img, width=250)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 4)\n",
    "    faces = img[y:y + h, x:x + w]\n",
    "    cv2.imwrite('face.jpg',faces)\n",
    "    \n",
    "image=cv2.imread('face.jpg')\n",
    "skin = extractSkin(image)\n",
    "unprocessed_dominant = extractDominantColor(skin, number_of_colors=1, hasThresholding=True)\n",
    "\n",
    "decimal_lower = (rgb_lower[0] * 256 * 256) + (rgb_lower[1] * 256) + rgb_lower[2]\n",
    "decimal_higher = (rgb_higher[0] * 256 * 256) + (rgb_higher[1] * 256) + rgb_higher[2]\n",
    "dominantColors = []\n",
    "for clr in unprocessed_dominant:\n",
    "    clr_decimal = int((clr['color'][0] * 256 * 256) + (clr['color'][1] * 256) + clr['color'][2])\n",
    "    if clr_decimal in range(decimal_lower,decimal_higher+1):\n",
    "        clr['decimal_color'] = clr_decimal\n",
    "        dominantColors.append(clr)\n",
    "\n",
    "colour_bar = plotColorBar(dominantColors)\n",
    "c=colour_bar[0][0]\n",
    "c=list(c)\n",
    "\n",
    "l=[]\n",
    "\n",
    "l.append(list(lr.predict([c])))\n",
    "l.append(list((rfr.predict([c]))))\n",
    "l.append(list(svc.predict([c])))\n",
    "l.append(list(knn.predict([c])))\n",
    "l.append(list(rc.predict([c])))\n",
    "\n",
    "k=[]\n",
    "for i in range(len(l)):\n",
    "    k.append(l[i][0])\n",
    "\n",
    "from collections import Counter\n",
    "freq=Counter(k)\n",
    "size=len(l)\n",
    "col=2\n",
    "for (key,v) in freq.items():\n",
    "    if(v>(size/2)):\n",
    "        col=key\n",
    "\n",
    "if col==1:\n",
    "    print('fair')\n",
    "elif col==0:\n",
    "    print('dark')\n",
    "elif col==2:\n",
    "    print('mild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
